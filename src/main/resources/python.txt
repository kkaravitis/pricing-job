Below is a self-contained Python script (requires TensorFlow 2.x) that:

Defines a trivial “sum + 1.0” model

Exports it as a TensorFlow SavedModel

Zips the exported directory into model.zip

Save this as e.g. build_sum1_model.py, install TensorFlow (pip install tensorflow), then run:

bash

python3 build_sum1_model.py /path/to/output/model_dir /path/to/output/model.zip
python
Αντιγραφή
Επεξεργασία
#!/usr/bin/env python3
import sys
import os
import shutil
import zipfile

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

def build_and_save_model(export_dir: str):
    # 1) Build a Keras model that sums its 3 inputs and adds a bias of +1.0
    n_features = 3
    model = keras.Sequential([
        # Lambda layer to enforce “sum + 1” behavior explicitly
        layers.Lambda(
            lambda x: tf.expand_dims(tf.reduce_sum(x, axis=1) + 1.0, axis=1),
            input_shape=(n_features,),
            name="sum_plus_one"
        )
    ])

    # 2) Wrap into a serving signature for SavedModel
    @tf.function(input_signature=[tf.TensorSpec([None, n_features], tf.float32)])
    def serve_fn(x):
        return {"predicted_price": model(x)}

    # 3) Save as a SavedModel
    tf.saved_model.save(
        model,
        export_dir,
        signatures={"serving_default": serve_fn}
    )
    print(f"SavedModel exported to: {export_dir}")

def zip_dir(src_dir: str, zip_path: str):
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
        for root, dirs, files in os.walk(src_dir):
            for name in files:
                abs_path = os.path.join(root, name)
                rel_path = os.path.relpath(abs_path, src_dir)
                zf.write(abs_path, rel_path)
    print(f"Zipped model directory to: {zip_path}")

def main():
    if len(sys.argv) != 3:
        print("Usage: build_sum1_model.py <export-model-dir> <output-zip-path>")
        sys.exit(1)
    export_dir = sys.argv[1]
    zip_path    = sys.argv[2]

    # ensure clean export directory
    if os.path.isdir(export_dir):
        shutil.rmtree(export_dir)
    os.makedirs(export_dir, exist_ok=True)

    build_and_save_model(export_dir)
    zip_dir(export_dir, zip_path)

if __name__ == "__main__":
    main()
How it works:

layers.Lambda(...) defines a layer that takes a batch x of shape (batch, 3), computes sum(x, axis=1) (shape (batch,)), adds 1.0, then expand_dims back to (batch, 1).

We wrap it in a TF serving signature so that SavedModelBundle.load(..., "serve") in Java will find the input/output names.

Finally we zip the entire directory so you get a model.zip which can be sent to your Kafka topic and consumed by the Flink job.

Once you run:

bash

python3 build_sum1_model.py ./exported_model ./model.zip
you’ll have a model.zip you can point your Flink tests at.